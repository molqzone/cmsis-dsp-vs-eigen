from __future__ import annotations

import argparse
import json
import math
from dataclasses import dataclass
from datetime import datetime
from datetime import timezone
from pathlib import Path
from typing import Iterable
from typing import Sequence

try:
    import matplotlib.pyplot as plt
    import pandas as pd
    _IMPORT_ERROR: Exception | None = None
except ImportError as exc:  # pragma: no cover - runtime dependency
    plt = None  # type: ignore[assignment]
    pd = None  # type: ignore[assignment]
    _IMPORT_ERROR = exc

from full_matrix_common import BuildProfile
from full_matrix_common import EXPECTED_INV_SIZES
from full_matrix_common import EXPECTED_MUL_SIZES
from full_matrix_common import SampleRecord
from full_matrix_common import default_profiles
from full_matrix_common import detect_crossover
from full_matrix_common import parse_profile_names
from full_matrix_common import parse_run_lines
from full_matrix_common import validate_records


@dataclass(frozen=True)
class ReportPaths:
    """Groups report generation paths."""

    repo_dir: Path
    input_root: Path
    output_md: Path
    output_dir: Path


def parse_args() -> argparse.Namespace:
    """Parses report generator CLI args."""

    parser = argparse.ArgumentParser(description="Generate report_full_matrix.md")
    parser.add_argument(
        "--input-root",
        default="build/bench_matrix",
        help="Root directory containing <profile>/samples_release.",
    )
    parser.add_argument(
        "--output-md",
        default="report_full_matrix.md",
        help="Output markdown report path.",
    )
    parser.add_argument(
        "--output-dir",
        default="benchmark_analysis/output/full_matrix",
        help="Output directory for plots and summary CSV.",
    )
    parser.add_argument("--profiles", default="C1,C2,C3,C4,C5,C6,C7,C8,C9,C10")
    parser.add_argument("--strict", action="store_true")
    return parser.parse_args()


def build_paths(args: argparse.Namespace) -> ReportPaths:
    """Builds absolute path object from args."""

    repo_dir = Path(__file__).resolve().parents[1]
    input_root = Path(args.input_root)
    if not input_root.is_absolute():
        input_root = repo_dir / input_root
    output_md = Path(args.output_md)
    if not output_md.is_absolute():
        output_md = repo_dir / output_md
    output_dir = Path(args.output_dir)
    if not output_dir.is_absolute():
        output_dir = repo_dir / output_dir
    return ReportPaths(
        repo_dir=repo_dir, input_root=input_root, output_md=output_md, output_dir=output_dir
    )


def load_profile_meta(profile_dir: Path) -> dict[str, object]:
    """Loads profile metadata generated by run_full_matrix."""

    meta_file = profile_dir / "profile_meta.json"
    if not meta_file.is_file():
        return {}
    return json.loads(meta_file.read_text(encoding="utf-8"))


def records_to_dicts(
    profile: str,
    run_id: str,
    records: Iterable[SampleRecord],
) -> list[dict[str, object]]:
    """Converts SampleRecord list into DataFrame-ready dict list."""

    rows: list[dict[str, object]] = []
    for rec in records:
        rows.append(
            {
                "profile": profile,
                "run_id": run_id,
                "op": rec.op,
                "n": rec.n,
                "repeat": rec.repeat,
                "warmup": rec.warmup,
                "eigen_avg_cycles": rec.eigen_avg_cycles,
                "cmsis_avg_cycles": rec.cmsis_avg_cycles,
                "cmsis_over_eigen": rec.cmsis_over_eigen,
                "eigen_over_cmsis": (1.0 / rec.cmsis_over_eigen) if rec.cmsis_over_eigen > 0 else float("inf"),
                "error_l2": rec.error_l2,
                "valid": rec.valid,
                "invalid": rec.invalid,
                "build_mode": rec.build_mode,
            }
        )
    return rows


def load_profile_runs(profile: str, profile_dir: Path, strict: bool) -> pd.DataFrame:
    """Loads all run_*.csv for one profile."""

    samples_dir = profile_dir / "samples_release"
    if not samples_dir.is_dir():
        if strict:
            raise FileNotFoundError(f"samples_release missing for {profile}: {samples_dir}")
        return pd.DataFrame()

    rows: list[dict[str, object]] = []
    run_files = sorted(samples_dir.glob("run_*.csv"))
    if not run_files and strict:
        raise RuntimeError(f"No run_*.csv found for {profile} in {samples_dir}")

    for run_file in run_files:
        lines = run_file.read_text(encoding="utf-8", errors="ignore").splitlines()
        records = parse_run_lines(lines)
        validate_records(records, expected_repeat=records[0].repeat)
        rows.extend(records_to_dicts(profile, run_file.stem, records))

    if not rows:
        return pd.DataFrame()
    return pd.DataFrame(rows)


def compute_stats(df: pd.DataFrame) -> pd.DataFrame:
    """Computes mean/var/std/95%CI by profile/op/n."""

    group = df.groupby(["profile", "op", "n"], as_index=False)
    stats = group.agg(
        runs=("run_id", "nunique"),
        eigen_mean=("eigen_avg_cycles", "mean"),
        eigen_var=("eigen_avg_cycles", "var"),
        eigen_std=("eigen_avg_cycles", "std"),
        cmsis_mean=("cmsis_avg_cycles", "mean"),
        cmsis_var=("cmsis_avg_cycles", "var"),
        cmsis_std=("cmsis_avg_cycles", "std"),
        eigen_over_cmsis_mean=("eigen_over_cmsis", "mean"),
        eigen_over_cmsis_var=("eigen_over_cmsis", "var"),
        eigen_over_cmsis_std=("eigen_over_cmsis", "std"),
        cmsis_over_eigen_mean=("cmsis_over_eigen", "mean"),
        cmsis_over_eigen_var=("cmsis_over_eigen", "var"),
        cmsis_over_eigen_std=("cmsis_over_eigen", "std"),
        error_mean=("error_l2", "mean"),
        error_var=("error_l2", "var"),
        error_std=("error_l2", "std"),
    )
    stats["ci_mult"] = stats["runs"].apply(lambda n: 1.96 / math.sqrt(n))
    stats["eigen_ci"] = stats["eigen_std"] * stats["ci_mult"]
    stats["cmsis_ci"] = stats["cmsis_std"] * stats["ci_mult"]
    stats["eigen_over_cmsis_ci"] = stats["eigen_over_cmsis_std"] * stats["ci_mult"]
    stats["cmsis_over_eigen_ci"] = stats["cmsis_over_eigen_std"] * stats["ci_mult"]
    stats["error_ci"] = stats["error_std"] * stats["ci_mult"]
    stats["leader"] = stats["eigen_over_cmsis_mean"].apply(classify_leader)
    return stats


def classify_leader(speedup: float, tolerance: float = 1e-6) -> str:
    """Classifies winner by speedup (Eigen/CMSIS)."""

    if abs(speedup - 1.0) <= tolerance:
        return "Tie"
    return "CMSIS" if speedup > 1.0 else "Eigen"


def to_cmsis_over_eigen(speedup: float) -> float:
    """Converts speedup (Eigen/CMSIS) to CMSIS/Eigen."""

    if speedup <= 0:
        return float("inf")
    return 1.0 / speedup


def speedup_axis_to_cmsis_over_eigen(y):
    """Axis transform: speedup -> CMSIS/Eigen, guarding non-positive values."""

    safe = y + (y <= 0) * 1e-12
    return 1.0 / safe


def cmsis_over_eigen_axis_to_speedup(y):
    """Axis transform: CMSIS/Eigen -> speedup, guarding non-positive values."""

    safe = y + (y <= 0) * 1e-12
    return 1.0 / safe


def plot_profile_cycles(stats: pd.DataFrame, profile: str, op: str, out_path: Path) -> None:
    """Plots profile-specific cycles with 95%CI."""

    sub = stats[(stats["profile"] == profile) & (stats["op"] == op)].sort_values("n")
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.errorbar(sub["n"], sub["eigen_mean"], yerr=sub["eigen_ci"], marker="o", label="Eigen")
    ax.errorbar(sub["n"], sub["cmsis_mean"], yerr=sub["cmsis_ci"], marker="s", label="CMSIS")
    ax.set_title(f"{profile} {op.upper()} cycles (mean ±95%CI)")
    ax.set_xlabel("Matrix size N")
    ax.set_ylabel("Average cycles")
    ax.set_yscale("log")
    ax.grid(True, which="both", linestyle=":", alpha=0.4)
    ax.legend()
    fig.tight_layout()
    fig.savefig(out_path, dpi=160)
    plt.close(fig)


def plot_profile_eigen_over_cmsis(
    stats: pd.DataFrame, profile: str, op: str, out_path: Path
) -> None:
    """Plots profile-specific speedup Eigen/CMSIS with 95%CI."""

    sub = stats[(stats["profile"] == profile) & (stats["op"] == op)].sort_values("n")
    fig, ax = plt.subplots(figsize=(10, 6))
    speedup = sub["eigen_over_cmsis_mean"]
    x_values = sub["n"]
    ax.fill_between(
        x_values,
        speedup,
        1.0,
        where=speedup >= 1.0,
        color="#d6f5dd",
        alpha=0.55,
        interpolate=True,
        label="CMSIS faster zone (>1)",
    )
    ax.fill_between(
        x_values,
        speedup,
        1.0,
        where=speedup < 1.0,
        color="#ffe2cf",
        alpha=0.55,
        interpolate=True,
        label="Eigen faster zone (<1)",
    )
    ax.errorbar(
        x_values,
        speedup,
        yerr=sub["eigen_over_cmsis_ci"],
        marker="o",
        linewidth=2.0,
        color="#1d4ed8",
        label=f"{profile} speedup",
    )
    ax.axhline(1.0, color="black", linestyle="--", linewidth=1.2)
    ax.set_title(f"{profile} {op.upper()} speedup Eigen/CMSIS (mean ±95%CI)")
    ax.set_xlabel("Matrix size N")
    ax.set_ylabel("Speedup Eigen/CMSIS (higher => CMSIS faster)")
    ax.set_yscale("log")
    ax.grid(True, which="both", linestyle=":", alpha=0.4)
    sec = ax.secondary_yaxis(
        "right",
        functions=(speedup_axis_to_cmsis_over_eigen, cmsis_over_eigen_axis_to_speedup),
    )
    sec.set_ylabel("CMSIS/Eigen (lower => CMSIS faster)")
    ax.legend()
    fig.tight_layout()
    fig.savefig(out_path, dpi=160)
    plt.close(fig)


def plot_cross_profile_eigen_over_cmsis(
    stats: pd.DataFrame, profiles: Sequence[str], op: str, out_path: Path
) -> None:
    """Plots Eigen/CMSIS speedup curves of all profiles for one operation."""

    fig, ax = plt.subplots(figsize=(11, 6))
    visible_profiles = 0
    for profile in profiles:
        sub = stats[(stats["profile"] == profile) & (stats["op"] == op)].sort_values("n")
        if sub.empty:
            continue
        visible_profiles += 1
        ax.plot(
            sub["n"],
            sub["eigen_over_cmsis_mean"],
            marker="o",
            label=profile,
        )
    speedup_values = stats[stats["op"] == op]["eigen_over_cmsis_mean"]
    positive_speedup = speedup_values[speedup_values > 0]
    speedup_max = float(positive_speedup.max()) if not positive_speedup.empty else 2.0
    speedup_min = float(positive_speedup.min()) if not positive_speedup.empty else 0.5
    ax.axhspan(1.0, speedup_max * 1.05, color="#d6f5dd", alpha=0.25)
    ax.axhspan(speedup_min * 0.95, 1.0, color="#ffe2cf", alpha=0.20)
    ax.axhline(1.0, color="black", linestyle="--", linewidth=1.2)
    ax.set_title(f"{op.upper()} speedup Eigen/CMSIS by profile")
    ax.set_xlabel("Matrix size N")
    ax.set_ylabel("Speedup Eigen/CMSIS (higher => CMSIS faster)")
    ax.set_yscale("log")
    ax.grid(True, linestyle=":", alpha=0.4)
    ncol = 3 if visible_profiles <= 6 else 4
    ax.legend(ncol=ncol, fontsize=9)
    sec = ax.secondary_yaxis(
        "right",
        functions=(speedup_axis_to_cmsis_over_eigen, cmsis_over_eigen_axis_to_speedup),
    )
    sec.set_ylabel("CMSIS/Eigen")
    fig.tight_layout()
    fig.savefig(out_path, dpi=160)
    plt.close(fig)


def plot_cross_profile_eigen_over_cmsis_box(
    stats: pd.DataFrame, profiles: Sequence[str], op: str, out_path: Path
) -> None:
    """Plots profile ranking by Eigen/CMSIS speedup distribution."""

    data: list[list[float]] = []
    labels: list[str] = []
    for profile in profiles:
        sub = stats[(stats["profile"] == profile) & (stats["op"] == op)].sort_values("n")
        if sub.empty:
            continue
        data.append(sub["eigen_over_cmsis_mean"].tolist())
        labels.append(profile)

    if not data:
        return

    fig, ax = plt.subplots(figsize=(11, 6))
    try:
        ax.boxplot(data, tick_labels=labels, showmeans=True)
    except TypeError:
        ax.boxplot(data, labels=labels, showmeans=True)
    ax.axhline(1.0, color="black", linestyle="--", linewidth=1.2)
    ax.set_title(f"{op.upper()} speedup distribution (Eigen/CMSIS)")
    ax.set_xlabel("Profile")
    ax.set_ylabel("Speedup Eigen/CMSIS (higher => CMSIS faster)")
    ax.grid(True, axis="y", linestyle=":", alpha=0.4)
    fig.tight_layout()
    fig.savefig(out_path, dpi=160)
    plt.close(fig)


def _curve_signature(
    sub: pd.DataFrame,
    value_col: str,
    round_digits: int = 9,
) -> tuple[tuple[int, float], ...]:
    """Builds a normalized signature for grouping identical profile curves."""

    signature: list[tuple[int, float]] = []
    ordered = sub.sort_values("n")
    for _, row in ordered.iterrows():
        signature.append((int(row["n"]), round(float(row[value_col]), round_digits)))
    return tuple(signature)


def group_profiles_for_plot(
    stats: pd.DataFrame,
    profiles: Sequence[str],
    op: str,
    value_col: str,
    round_digits: int = 5,
) -> list[tuple[list[str], pd.DataFrame]]:
    """Groups profiles with identical plotted curves.

    Returns one representative DataFrame per group and the member profile list.
    """

    grouped: dict[tuple[tuple[int, float], ...], tuple[list[str], pd.DataFrame]] = {}
    order: list[tuple[tuple[int, float], ...]] = []
    for profile in profiles:
        sub = stats[(stats["profile"] == profile) & (stats["op"] == op)].sort_values("n")
        if sub.empty:
            continue
        signature = _curve_signature(sub, value_col=value_col, round_digits=round_digits)
        if signature not in grouped:
            grouped[signature] = ([profile], sub)
            order.append(signature)
        else:
            grouped[signature][0].append(profile)
    return [grouped[key] for key in order]


def format_group_label(members: Sequence[str]) -> str:
    """Formats merged profile labels for plot legends."""

    if len(members) == 1:
        return members[0]
    return "/".join(members)


def group_profiles_by_full_curve(
    stats: pd.DataFrame,
    profiles: Sequence[str],
    round_digits: int = 5,
) -> list[tuple[list[str], str]]:
    """Groups profiles by speedup curve signature across mul/inv.

    Returns:
        List of `(members, representative_profile)`.
    """

    grouped: dict[tuple[tuple[str, int, float], ...], tuple[list[str], str]] = {}
    order: list[tuple[tuple[str, int, float], ...]] = []
    for profile in profiles:
        sub = stats[stats["profile"] == profile].sort_values(["op", "n"])
        if sub.empty:
            continue
        signature: list[tuple[str, int, float]] = []
        for _, row in sub.iterrows():
            signature.append(
                (
                    str(row["op"]),
                    int(row["n"]),
                    round(float(row["eigen_over_cmsis_mean"]), round_digits),
                )
            )
        sig_key = tuple(signature)
        if sig_key not in grouped:
            grouped[sig_key] = ([profile], profile)
            order.append(sig_key)
        else:
            grouped[sig_key][0].append(profile)
    return [grouped[key] for key in order]


def get_speedup(stats: pd.DataFrame, profile: str, op: str, n: int) -> float:
    """Gets eigen_over_cmsis_mean for one point."""

    sub = stats[
        (stats["profile"] == profile) & (stats["op"] == op) & (stats["n"] == n)
    ]["eigen_over_cmsis_mean"]
    if sub.empty:
        raise KeyError(f"Missing speedup for {profile}-{op}-{n}")
    return float(sub.iloc[0])


def format_stats_table(stats: pd.DataFrame, profile: str, op: str) -> str:
    """Formats markdown table for one profile/op summary."""

    sub = stats[(stats["profile"] == profile) & (stats["op"] == op)].sort_values("n")
    lines = [
        "| n | eigen_mean | eigen_var | eigen_95%CI | cmsis_mean | cmsis_var | cmsis_95%CI | eigen_over_cmsis_mean | eigen_over_cmsis_var | eigen_over_cmsis_95%CI | leader | error_mean |",
        "|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|---|---:|",
    ]
    for _, row in sub.iterrows():
        lines.append(
            "| {n} | {em:.2f} | {ev:.2f} | ±{eci:.2f} | {cm:.2f} | {cv:.2f} | ±{cci:.2f} | {rm:.3f} | {rv:.5f} | ±{rci:.3f} | {ld} | {err:.8f} |".format(
                n=int(row["n"]),
                em=row["eigen_mean"],
                ev=row["eigen_var"],
                eci=row["eigen_ci"],
                cm=row["cmsis_mean"],
                cv=row["cmsis_var"],
                cci=row["cmsis_ci"],
                rm=row["eigen_over_cmsis_mean"],
                ld=row["leader"],
                rv=row["eigen_over_cmsis_var"],
                rci=row["eigen_over_cmsis_ci"],
                err=row["error_mean"],
            )
        )
    return "\n".join(lines)


def _profile_sort_key(profile: str) -> tuple[int, str]:
    """Sort key for profile names like C1..C10."""

    suffix = profile[1:] if profile.startswith("C") else profile
    if suffix.isdigit():
        return (int(suffix), profile)
    return (10_000, profile)


def _mean_curve_diff(
    stats: pd.DataFrame,
    profile_a: str,
    profile_b: str,
) -> float:
    """Computes mean absolute eigen/cmsis curve difference between two profiles."""

    sub_a = stats[stats["profile"] == profile_a][["op", "n", "eigen_over_cmsis_mean"]]
    sub_b = stats[stats["profile"] == profile_b][["op", "n", "eigen_over_cmsis_mean"]]
    merged = pd.merge(
        sub_a,
        sub_b,
        on=["op", "n"],
        suffixes=("_a", "_b"),
    )
    if merged.empty:
        return float("nan")
    return float((merged["eigen_over_cmsis_mean_a"] - merged["eigen_over_cmsis_mean_b"]).abs().mean())


def build_profile_priority_section(stats: pd.DataFrame, profiles: Sequence[str]) -> str:
    """Builds profile retention priority recommendation for C1~C10."""

    lines: list[str] = []
    lines.append("### 7.1 实验轮次优先级（C1~C10）")
    if not profiles:
        lines.append("- 无可用 profile，无法给出优先级建议。")
        lines.append("")
        return "\n".join(lines)

    ordered_profiles = sorted(set(profiles), key=_profile_sort_key)

    keep: list[str] = []
    # Baseline + control
    if "C1" in ordered_profiles:
        keep.append("C1")
    if "C3" in ordered_profiles:
        keep.append("C3")
    # Fast-math / Ofast family: prefer C4 as representative, fallback C5.
    for candidate in ("C4", "C5"):
        if candidate in ordered_profiles:
            keep.append(candidate)
            break
    # Loop-unroll control
    if "C7" in ordered_profiles:
        keep.append("C7")
    # Debug optimization sensitivity
    if "C9" in ordered_profiles:
        keep.append("C9")
    # Size-oriented family: prefer Oz(C10), fallback Os(C6).
    for candidate in ("C10", "C6"):
        if candidate in ordered_profiles:
            keep.append(candidate)
            break

    # Add any highly distinctive profile not yet covered.
    if "C1" in ordered_profiles:
        for profile in ordered_profiles:
            if profile in keep:
                continue
            diff = _mean_curve_diff(stats, profile, "C1")
            if not math.isnan(diff) and diff >= 0.18:
                keep.append(profile)

    # Deduplicate while preserving order.
    seen: set[str] = set()
    keep = [p for p in keep if not (p in seen or seen.add(p))]
    downgrade = [p for p in ordered_profiles if p not in keep]

    lines.append(f"- 高信息量（建议默认保留）：`{', '.join(keep)}`")
    if downgrade:
        lines.append(f"- 可降权/按需复测：`{', '.join(downgrade)}`")
    else:
        lines.append("- 可降权/按需复测：`无`")
    lines.append("- 依据口径：`eigen/cmsis` 全点位曲线相对 C1 的平均绝对差（L1），并结合编译策略覆盖面。")
    lines.append("")
    lines.append("| profile | mean_abs_curve_diff_vs_C1 | nearest_profile | nearest_diff |")
    lines.append("|---|---:|---|---:|")
    for profile in ordered_profiles:
        if profile == "C1":
            lines.append("| C1 | 0.000000 | C1 | 0.000000 |")
            continue
        diff_c1 = _mean_curve_diff(stats, profile, "C1")
        nearest_profile = ""
        nearest_diff = float("nan")
        for other in ordered_profiles:
            if other == profile:
                continue
            d = _mean_curve_diff(stats, profile, other)
            if math.isnan(d):
                continue
            if math.isnan(nearest_diff) or d < nearest_diff:
                nearest_diff = d
                nearest_profile = other
        diff_text = f"{diff_c1:.6f}" if not math.isnan(diff_c1) else "nan"
        nearest_text = f"{nearest_diff:.6f}" if not math.isnan(nearest_diff) else "nan"
        lines.append(f"| {profile} | {diff_text} | {nearest_profile} | {nearest_text} |")
    lines.append("")
    return "\n".join(lines)


def build_analysis_section(stats: pd.DataFrame, profiles: Sequence[str]) -> str:
    """Builds PLAN-aligned analysis text section."""

    lines: list[str] = []
    lines.append("## 5. 跨条件分析（对齐 PLAN.md）")
    lines.append("")
    if not profiles:
        lines.append("- 无可分析 profile（样本数据缺失）。")
        lines.append("")
        return "\n".join(lines)

    lines.append("### 5.1 小矩阵优势区（N=3,4）")
    for profile in profiles:
        r3 = get_speedup(stats, profile, "mul", 3)
        r4 = get_speedup(stats, profile, "mul", 4)
        if r3 > 1.0 and r4 > 1.0:
            winner = "CMSIS 更快"
        elif r3 < 1.0 and r4 < 1.0:
            winner = "Eigen 更快"
        else:
            winner = "各有胜负"
        lines.append(f"- `{profile}`: mul@3={r3:.3f}, mul@4={r4:.3f} -> {winner}")
    lines.append("")

    lines.append("### 5.2 临界点识别（eigen/cmsis 穿越 1.0）")
    for profile in profiles:
        mul_pairs = list(
            stats[(stats["profile"] == profile) & (stats["op"] == "mul")][
                ["n", "eigen_over_cmsis_mean"]
            ].itertuples(index=False, name=None)
        )
        inv_pairs = list(
            stats[(stats["profile"] == profile) & (stats["op"] == "inv")][
                ["n", "eigen_over_cmsis_mean"]
            ].itertuples(index=False, name=None)
        )
        mul_cross = detect_crossover(mul_pairs)
        inv_cross = detect_crossover(inv_pairs)
        lines.append(
            f"- `{profile}`: mul 临界点={mul_cross if mul_cross else '未穿越'}, "
            f"inv 临界点={inv_cross if inv_cross else '未穿越'}"
        )
    lines.append("")

    lines.append("### 5.3 大矩阵趋势（mul, N>=32）")
    for profile in profiles:
        sub = stats[
            (stats["profile"] == profile)
            & (stats["op"] == "mul")
            & (stats["n"] >= 32)
        ]
        speedup_avg = float(sub["eigen_over_cmsis_mean"].mean())
        inverse_avg = float(sub["cmsis_over_eigen_mean"].mean())
        lines.append(
            f"- `{profile}`: 平均 eigen/cmsis={speedup_avg:.3f}，对应 cmsis/eigen={inverse_avg:.3f}"
        )
    lines.append("")

    lines.append("### 5.4 编译条件敏感性（C1~C10）")
    spread = (
        stats.groupby(["op", "n"], as_index=False)["eigen_over_cmsis_mean"]
        .agg(["mean", "std"])
        .reset_index()
    )
    avg_std = float(spread["std"].fillna(0.0).mean())
    lines.append(f"- 全点位 eigen/cmsis 标准差均值：`{avg_std:.4f}`（值越大表示对编译条件越敏感）")
    lines.append("")

    lines.append("### 5.5 性能-精度权衡（C4/C5 vs C1）")
    for target in ("C4", "C5"):
        if target not in profiles:
            continue
        base = stats[(stats["profile"] == "C1")][["op", "n", "eigen_over_cmsis_mean", "error_mean"]]
        cur = stats[(stats["profile"] == target)][["op", "n", "eigen_over_cmsis_mean", "error_mean"]]
        merged = pd.merge(base, cur, on=["op", "n"], suffixes=("_c1", "_cur"))
        speedup_delta = (
            (merged["eigen_over_cmsis_mean_cur"] - merged["eigen_over_cmsis_mean_c1"])
            / merged["eigen_over_cmsis_mean_c1"]
        ).mean() * 100.0
        err_delta = ((merged["error_mean_cur"] - merged["error_mean_c1"]) / merged["error_mean_c1"].replace(0, 1e-12)).mean() * 100.0
        lines.append(
            f"- `{target}` 相比 `C1`: eigen/cmsis 变化 `{speedup_delta:.2f}%`，error 变化 `{err_delta:.2f}%`"
        )
    lines.append("")

    lines.append("### 5.6 展开策略影响（C7 vs C1）")
    if "C7" in profiles and "C1" in profiles:
        for n in (3, 4, 6, 8, 10, 16):
            c1 = get_speedup(stats, "C1", "mul", n)
            c7 = get_speedup(stats, "C7", "mul", n)
            lines.append(f"- mul@{n}: C1={c1:.3f}, C7={c7:.3f}, 差值={c7-c1:+.3f}")
    lines.append("")

    lines.append("### 5.7 内联策略影响（C8 vs C1）")
    if "C8" in profiles and "C1" in profiles:
        for n in (3, 4, 6, 8, 10, 16):
            c1 = get_speedup(stats, "C1", "mul", n)
            c8 = get_speedup(stats, "C8", "mul", n)
            lines.append(f"- mul@{n}: C1={c1:.3f}, C8={c8:.3f}, 差值={c8-c1:+.3f}")
    lines.append("")

    return "\n".join(lines)


def build_report_markdown(
    paths: ReportPaths,
    profiles: Sequence[BuildProfile],
    profile_meta: dict[str, dict[str, object]],
    df: pd.DataFrame,
    stats: pd.DataFrame,
) -> str:
    """Builds final report_full_matrix markdown."""

    profile_names = [p.name for p in profiles]
    available_profile_names = [
        profile for profile in profile_names if not stats[stats["profile"] == profile].empty
    ]
    missing_profile_names = [
        profile for profile in profile_names if profile not in available_profile_names
    ]
    run_counts = sorted(df.groupby("profile")["run_id"].nunique().to_dict().items())
    build_modes = ", ".join(sorted(df["build_mode"].unique()))
    min_repeat = int(df["repeat"].min())
    max_repeat = int(df["repeat"].max())

    lines: list[str] = []
    lines.append("# 全量基准实验报告（C1~C10）")
    lines.append("")
    lines.append("## 1. 关联计划与实验矩阵")
    lines.append(f"- 计划文件：`{paths.repo_dir / 'PLAN.md'}`")
    lines.append(f"- 覆盖 profile：`{', '.join(profile_names)}`")
    lines.append(f"- 采样 run 数（按 profile）：`{run_counts}`")
    lines.append(f"- build_mode：`{build_modes}`")
    lines.append(f"- repeat 范围：`{min_repeat} ~ {max_repeat}`")
    lines.append("")

    lines.append("## 2. 工具链与环境信息")
    ref_profile = profile_names[0]
    ref_meta = profile_meta.get(ref_profile, {})
    tools = ref_meta.get("tools", {})
    lines.append(f"- 生成时间：`{datetime.now(timezone.utc).isoformat()}`")
    if isinstance(tools, dict):
        for key in ("cube_cmake", "cube", "starm_clang", "jlink"):
            if key in tools:
                lines.append(f"- {key}: `{tools[key]}`")
    lines.append("")

    lines.append("## 2.1 编译参数矩阵（实际执行口径）")
    lines.append("| profile | CFLAGS | CXXFLAGS | LDFLAGS | uses_lto |")
    lines.append("|---|---|---|---|---|")
    for profile in profiles:
        meta = profile_meta.get(profile.name, {})
        cflags = str(meta.get("cflags", profile.cflags))
        cxxflags = str(meta.get("cxxflags", profile.cxxflags))
        ldflags = str(meta.get("ldflags", profile.ldflags))
        uses_lto = bool(meta.get("uses_lto", profile.uses_lto))
        lines.append(
            f"| {profile.name} | `{cflags}` | `{cxxflags}` | `{ldflags}` | `{uses_lto}` |"
        )
    lines.append("")

    lines.append("## 3. 数据完整性与口径校验")
    for profile in profile_names:
        sub = stats[(stats["profile"] == profile)]
        mul_sizes = sorted(sub[sub["op"] == "mul"]["n"].tolist())
        inv_sizes = sorted(sub[sub["op"] == "inv"]["n"].tolist())
        lines.append(
            f"- `{profile}`: mul={mul_sizes}, inv={inv_sizes}, "
            f"expected_mul={list(EXPECTED_MUL_SIZES)}, expected_inv={list(EXPECTED_INV_SIZES)}"
        )
    if missing_profile_names:
        lines.append(f"- 缺失样本（已跳过跨条件分析）：`{', '.join(missing_profile_names)}`")
    lines.append("")

    lines.append("## 4. 各编译条件结果（图表）")
    lines.append("")
    lines.append("- 图表口径：`speedup = Eigen / CMSIS`，`speedup > 1` 表示 CMSIS 更快，`speedup < 1` 表示 Eigen 更快。")
    lines.append("- 右侧副轴展示 `CMSIS/Eigen`，与板端原始字段 `cmsis_over_eigen` 对齐。")
    lines.append("- 各 profile 独立展示，不做曲线合并。")
    lines.append("")
    for idx, profile in enumerate(available_profile_names, start=1):
        lines.append(f"### 4.{idx} {profile}")
        lines.append(
            f"![{profile}_mul_cycles](benchmark_analysis/output/full_matrix/{profile}_mul_cycles.png)"
        )
        lines.append(
            f"![{profile}_inv_cycles](benchmark_analysis/output/full_matrix/{profile}_inv_cycles.png)"
        )
        lines.append(
            f"![{profile}_mul_eigen_over_cmsis](benchmark_analysis/output/full_matrix/{profile}_mul_eigen_over_cmsis.png)"
        )
        lines.append(
            f"![{profile}_inv_eigen_over_cmsis](benchmark_analysis/output/full_matrix/{profile}_inv_eigen_over_cmsis.png)"
        )
        lines.append("")

    lines.append("### 4.x 跨条件 speedup 曲线（Eigen/CMSIS）")
    lines.append("- 图中每条线对应一个 profile，不做自动合并。")
    lines.append(
        "![mul_eigen_over_cmsis_by_profile](benchmark_analysis/output/full_matrix/mul_eigen_over_cmsis_by_profile.png)"
    )
    lines.append(
        "![inv_eigen_over_cmsis_by_profile](benchmark_analysis/output/full_matrix/inv_eigen_over_cmsis_by_profile.png)"
    )
    lines.append(
        "![mul_eigen_over_cmsis_box_by_profile](benchmark_analysis/output/full_matrix/mul_eigen_over_cmsis_box_by_profile.png)"
    )
    lines.append(
        "![inv_eigen_over_cmsis_box_by_profile](benchmark_analysis/output/full_matrix/inv_eigen_over_cmsis_box_by_profile.png)"
    )
    lines.append("")

    lines.append(build_analysis_section(stats, available_profile_names))

    lines.append("## 6. 代码体积/Flash 惩罚（.text/.rodata/.data/.bss）")
    lines.append("| profile | .text | .rodata | .data | .bss |")
    lines.append("|---|---:|---:|---:|---:|")
    for profile in profile_names:
        meta = profile_meta.get(profile, {})
        mem = meta.get("memory", {})
        if isinstance(mem, dict):
            lines.append(
                f"| {profile} | {int(mem.get('text', 0))} | {int(mem.get('rodata', 0))} | "
                f"{int(mem.get('data', 0))} | {int(mem.get('bss', 0))} |"
            )
    lines.append("")

    lines.append("## 7. 结论与建议配置")
    c1_mul_cross = detect_crossover(
        list(
            stats[(stats["profile"] == "C1") & (stats["op"] == "mul")][
                ["n", "eigen_over_cmsis_mean"]
            ].itertuples(index=False, name=None)
        )
    )
    lines.append(
        f"- 基线 C1 的 mul 临界点：`{c1_mul_cross if c1_mul_cross else '未穿越'}`。"
    )
    lines.append(
        "- 建议优先使用 C1 作为默认发布配置，再按目标矩阵规模选择 C4/C5/C7/C8 做定向优化。"
    )
    lines.append("")
    lines.append(build_profile_priority_section(stats, available_profile_names))

    lines.append("## 8. 附录：全量统计表（按 profile）")
    for idx, profile in enumerate(available_profile_names, start=1):
        lines.append(f"### 8.{idx} {profile} mul")
        lines.append(format_stats_table(stats, profile, "mul"))
        lines.append("")
        lines.append(f"### 8.{idx} {profile} inv")
        lines.append(format_stats_table(stats, profile, "inv"))
        lines.append("")
    return "\n".join(lines).rstrip() + "\n"


def main() -> None:
    """Entry point for full matrix report generation."""

    args = parse_args()
    if pd is None or plt is None:
        raise RuntimeError(
            "matplotlib and pandas are required. Install dependencies in benchmark_analysis first."
        ) from _IMPORT_ERROR
    paths = build_paths(args)
    paths.output_dir.mkdir(parents=True, exist_ok=True)

    all_profiles = default_profiles()
    selected_names = parse_profile_names(args.profiles)
    selected_profiles: list[BuildProfile] = []
    for name in selected_names:
        if name not in all_profiles:
            raise ValueError(f"Unknown profile: {name}")
        selected_profiles.append(all_profiles[name])

    frames: list[pd.DataFrame] = []
    profile_meta: dict[str, dict[str, object]] = {}
    for profile in selected_profiles:
        profile_dir = paths.input_root / profile.name
        profile_meta[profile.name] = load_profile_meta(profile_dir)
        frame = load_profile_runs(profile.name, profile_dir, strict=args.strict)
        if not frame.empty:
            frames.append(frame)
        elif args.strict:
            raise RuntimeError(f"No data for profile {profile.name}")

    if not frames:
        raise RuntimeError("No benchmark data found.")
    df = pd.concat(frames, ignore_index=True)
    stats = compute_stats(df)
    data_profile_names = [
        p.name for p in selected_profiles if not stats[stats["profile"] == p.name].empty
    ]

    stats_csv = paths.output_dir / "summary_full_matrix.csv"
    stats.to_csv(stats_csv, index=False, encoding="utf-8")

    for profile in data_profile_names:
        plot_profile_cycles(
            stats, profile, "mul", paths.output_dir / f"{profile}_mul_cycles.png"
        )
        plot_profile_cycles(
            stats, profile, "inv", paths.output_dir / f"{profile}_inv_cycles.png"
        )
        plot_profile_eigen_over_cmsis(
            stats, profile, "mul", paths.output_dir / f"{profile}_mul_eigen_over_cmsis.png"
        )
        plot_profile_eigen_over_cmsis(
            stats, profile, "inv", paths.output_dir / f"{profile}_inv_eigen_over_cmsis.png"
        )

    plot_cross_profile_eigen_over_cmsis(
        stats,
        data_profile_names,
        "mul",
        paths.output_dir / "mul_eigen_over_cmsis_by_profile.png",
    )
    plot_cross_profile_eigen_over_cmsis(
        stats,
        data_profile_names,
        "inv",
        paths.output_dir / "inv_eigen_over_cmsis_by_profile.png",
    )
    plot_cross_profile_eigen_over_cmsis_box(
        stats,
        data_profile_names,
        "mul",
        paths.output_dir / "mul_eigen_over_cmsis_box_by_profile.png",
    )
    plot_cross_profile_eigen_over_cmsis_box(
        stats,
        data_profile_names,
        "inv",
        paths.output_dir / "inv_eigen_over_cmsis_box_by_profile.png",
    )

    report_md = build_report_markdown(
        paths=paths,
        profiles=selected_profiles,
        profile_meta=profile_meta,
        df=df,
        stats=stats,
    )
    paths.output_md.write_text(report_md, encoding="utf-8")
    print(f"Generated report: {paths.output_md}")
    print(f"Generated summary CSV: {stats_csv}")
    print(f"Generated plots: {paths.output_dir}")


if __name__ == "__main__":
    main()
